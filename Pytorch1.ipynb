{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "isWBXLQnijzl"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejtHlml-imnn"
      },
      "source": [
        "scalar1 = torch.tensor([1.])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY0IjoociuR9"
      },
      "source": [
        "scalar2 = torch.tensor([3.])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq_iCXB0ip32"
      },
      "source": [
        "add_scalar = scalar1 + scalar2"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwmweQHPiqrF",
        "outputId": "ba4b527b-fd36-407d-fa3a-9eea200cc335"
      },
      "source": [
        "add_scalar"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o55l1MISi1l5"
      },
      "source": [
        "sub_scalar = scalar1 - scalar2"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePgOsF6ajJ05",
        "outputId": "02fe4245-e530-46b1-89c3-3d403eca246f"
      },
      "source": [
        "torch.sub(scalar1, scalar2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbLQDpdZjPwR"
      },
      "source": [
        "vector1 = torch.tensor([1., 2., 3.])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PojcSPSdjWcT",
        "outputId": "87763650-90fd-48fa-8a9d-016cc65f9e52"
      },
      "source": [
        "vector1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUg5ZeH7jYbY"
      },
      "source": [
        "matrix1 = torch.tensor([[1.,2.],[3.,4.]])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOci0tMXjzSy",
        "outputId": "e63598b7-facf-4b57-df79-8b26147f4c50"
      },
      "source": [
        "matrix1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F44By9iSj0zi"
      },
      "source": [
        "# torch autograd \n",
        "# autograd란 자동미분엔진"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScbQFNTakphy"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  DEVICE = torch.device('cuda')\n",
        "else:\n",
        "  DEVICE = torch.device('cpu')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "FyEBAg1xk6qu",
        "outputId": "2b47e05c-c56e-4ddc-f19a-5ee5391a4f5b"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "INPUT_SIZE = 1000\n",
        "HIDDEN_SIZE = 100\n",
        "OUTPUT_SIZE = 10 \n",
        "\n",
        "''' BATCH SIZE는, 딥러닝 모델에서 파라미터를 업데이트 할 때 계산되는 데이터의 개수\n",
        "BATCH SIZE수만큼 데이터를 이용해 output을 계산하고 출력된 결괏값에 대한 오차를 계산, 64 -> input으로 이용되는 데이터가 64개 의미\n",
        "input size는 입력층의 노드 수를 의미, 입력데이터의 크기가 1000이라는 것을 의미, 1000크기의 벡터값 배치가64이므로 1000크기의 벡터를 64개 이용한다는 의미 = (64,1000)\n",
        "Hidden size는 딥러닝 모델에서 Input을 다수의 파라미터를 이용해 계산한 결과에 한 번 더 계산되는 파라미터 수를의미한다. 입력->은닉층으로 전달 됐을때 은닉층의 노드 수를 의미\n",
        "이 예제에서는 (64, 1000) Input들이 (1000, 100) 크기의 행렬과 행렬곱을계산함 '''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' BATCH SIZE는, 딥러닝 모델에서 파라미터를 업데이트 할 때 계산되는 데이터의 개수\\nBATCH SIZE수만큼 데이터를 이용해 output을 계산하고 출력된 결괏값에 대한 오차를 계산, 64 -> input으로 이용되는 데이터가 64개 의미\\ninput size는 입력층의 노드 수를 의미, 입력데이터의 크기가 1000이라는 것을 의미, 1000크기의 벡터값 배치가64이므로 1000크기의 벡터를 64개 이용한다는 의미 = (64,1000)\\nHidden size는 딥러닝 모델에서 Input을 다수의 파라미터를 이용해 계산한 결과에 한 번 더 계산되는 파라미터 수를의미한다. 입력->은닉층으로 전달 됐을때 은닉층의 노드 수를 의미\\n이 예제에서는 (64, 1000) Input들이 (1000, 100) 크기의 행렬과 행렬곱을계산함 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1r9wj6PpHPs"
      },
      "source": [
        "# torch.randn - 평균이 0이고 표준편차가 1인 가우시안 정규분포를 이용해 텐서 생성\n",
        "\n",
        "x = torch.randn(BATCH_SIZE,\n",
        "                INPUT_SIZE,\n",
        "                device = DEVICE,\n",
        "                dtype = torch.float,\n",
        "                requires_grad = False)\n",
        "y = torch.randn(BATCH_SIZE,\n",
        "                OUTPUT_SIZE,\n",
        "                device = DEVICE,\n",
        "                dtype = torch.float,\n",
        "                requires_grad = False)\n",
        "w1 = torch.randn(INPUT_SIZE,\n",
        "                 HIDDEN_SIZE,\n",
        "                 device = DEVICE,\n",
        "                 dtype = torch.float,\n",
        "                 requires_grad = True) # 역전파를통한 업데이트해야되는 대상이면 True \n",
        "w2 = torch.randn(HIDDEN_SIZE,\n",
        "                 OUTPUT_SIZE,\n",
        "                 device = DEVICE,\n",
        "                 dtype = torch.float,\n",
        "                 requires_grad = True)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3K_2mHmpx8W",
        "outputId": "553a3c88-93db-476b-c163-70db8968044b"
      },
      "source": [
        "learning_rate = 1e-6 # learning_rate란, 어느정도 크기로 기울기가 줄어드는 지점까지 이동하겠는가 \n",
        "for t in range(1, 501):\n",
        "  y_pred = x.mm(w1).clamp(min=0).mm(w2) # mm은 matrix mul , 여기서 clamp는 relu와 같은 역할을 함 \n",
        "\n",
        "  loss = (y_pred - y).pow(2).sum()\n",
        "  if t % 100 == 0:\n",
        "    print(\"iteration: \", t, \"\\t\", \"Loss: \", loss.item())\n",
        "  loss.backward() # 각 파라미터 값에 대해 Gradient를 계산하고 Back Propagation진행한다는 것을 의미 \n",
        "\n",
        "  with torch.no_grad(): # Gradient를 고정한다는 의미 \n",
        "    w1 -= learning_rate * w1.grad \n",
        "    w2 -= learning_rate * w2.grad\n",
        "\n",
        "    w1.grad.zero_() # 파라미터를 업데이트 했다면, gradient를 0으로 초기화해 다음 반복문 진행할수있도록 함. \n",
        "    w2.grad.zero_()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration:  100 \t Loss:  nan\n",
            "iteration:  200 \t Loss:  nan\n",
            "iteration:  300 \t Loss:  nan\n",
            "iteration:  400 \t Loss:  nan\n",
            "iteration:  500 \t Loss:  nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_GWbvefpypa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}